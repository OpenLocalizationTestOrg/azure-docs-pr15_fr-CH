<properties
    pageTitle="Importer des données dans un Studio de formation de Machine à partir de sources de données en ligne | Microsoft Azure"
    description="Comment importer vos données de formation Azure Machine Learning Studio à partir de différentes sources en ligne."
    keywords="importer des données, format de données, types de données, les sources de données, les données de formation"
    services="machine-learning"
    documentationCenter=""
    authors="bradsev"
    manager="jhubbard"
    editor="cgronlun"/>

<tags
    ms.service="machine-learning"
    ms.workload="data-services"
    ms.tgt_pltfrm="na"
    ms.devlang="na"
    ms.topic="article"
    ms.date="09/19/2016"
    ms.author="bradsev;garye" />


# <a name="import-data-into-azure-machine-learning-studio-from-various-online-data-sources-with-the-import-data-module"></a>Importer des données dans un Studio de formation Azure Machine à partir de diverses sources de données en ligne avec le module d’importation de données

Cet article décrit la prise en charge pour l’importation de données en ligne à partir de différentes sources et les informations nécessaires pour importer des données provenant de ces sources dans une expérience d’apprentissage automatique de Azure.

> [AZURE.NOTE] Cet article fournit des informations générales à propos de l' [Importation des données] [ import-data] module. Pour plus d’informations sur les types de données, vous pouvez accéder, formats, des paramètres et des réponses aux questions courantes, consultez la rubrique de référence de module pour [Importer des données] [ import-data] module.

<!-- -->

[AZURE.INCLUDE [import-data-into-aml-studio-selector](../../includes/machine-learning-import-data-into-aml-studio.md)]

## <a name="introduction"></a>Introduction

Vous pouvez accéder aux données à partir de dans le Studio de formation de Machine Azure à partir de plusieurs sources de données en ligne pendant l’exécution de votre expérience en utilisant les [Données d’importation] [ import-data] module :

- Une URL Web à l’aide de HTTP
- Hadoop à l’aide de HiveQL
- Stockage des objets blob Azure
- Table Azure
- Base de données SQL Azure ou de SQL Server sur Azure VM
- Base de données de SQL Server sur site
- Un fournisseur, OData actuellement de flux de données
 
Le flux de travail pour la réalisation des expériences dans Azure Machine Learning Studio est constitué de composants de glisser-déplacer sur le canevas. Pour accéder aux sources de données en ligne, ajouter les [Données d’importation] [ import-data] module à votre expérience, sélectionnez la **source de données**et ensuite fournir les paramètres nécessaires pour accéder aux données. Les sources de données en ligne qui sont pris en charge sont répertoriés dans le tableau ci-dessous. Ce tableau récapitule également les paramètres qui sont utilisés pour accéder aux données et les formats de fichier pris en charge.

Notez que dans la mesure où cette formation d’accès aux données pendant l’exécution de votre expérience, il est disponible uniquement dans cette expérimentation. Par comparaison, les données qui ont été stockées dans un module de groupe de données sont disponibles pour toute expérience dans votre espace de travail.

> [AZURE.IMPORTANT] Actuellement, les [Données d’importation] [ import-data] et [Exportation de données] [ export-data] modules peuvent lire et écrire des données uniquement à partir de stockage Azure créé à l’aide du modèle de déploiement standard. En d’autres termes, le nouveau type de compte de stockage des objets Blob Azure qui offre un niveau d’accès de stockage à chaud ou la couche d’accès aux frais de stockage n'est pas encore pris en charge. 

> En règle générale, les comptes de stockage Azure que vous avez créées avant la disponibilité de cette option de service ne doivent pas être affectées. Si vous avez besoin créer un nouveau compte, sélectionnez **classique** pour le modèle de déploiement, ou utiliser le Gestionnaire de ressources et pour le **type de compte**, sélectionnez **usage général** au lieu de **stockage des objets Blob**. 

> Pour plus d’informations, consultez [le stockage Blob Azure : à chaud et refroidir des niveaux de stockage](../storage/storage-blob-storage-tiers.md).



## <a name="supported-online-data-sources"></a>Prise en charge des sources de données en ligne
Module d’apprentissage automatique, **Importation de données** Azure prend en charge les sources de données suivantes :

Source de données | Description | Paramètres |
---|---|---|
URL du site Web via HTTP |Lit les données de valeurs séparées par des virgules (CSV), les valeurs séparées par des tabulations (TSV), format de fichier de relation d’attribut (ARFF) et les formats de Machines vectorielles (SVM-clair), à partir de n’importe quelle URL web qui utilise le protocole HTTP | <b>URL</b>: Spécifie le nom complet du fichier, y compris l’URL du site et le nom de fichier avec n’importe quelle extension. <br/><br/><b>Format de données</b>: Spécifie les formats d’une des données prises en charge : CSV, TSV, ARFF ou lumière SVM. Si les données comportent une ligne d’en-tête, il est utilisé pour assigner des noms de colonne.|
Hadoop/très|Lit les données à partir d’un stockage distribué dans Hadoop. Vous spécifiez les données souhaitées à l’aide de HiveQL, un langage de requête de type SQL. HiveQL peut également servir à agréger des données et d’effectuer le filtrage avant d’ajouter les données à un Studio de formation de Machine de données.|<b>Requête de base de données de la ruche</b>: Spécifie la requête de la ruche permet de générer les données.<br/><br/><b>URI du serveur HCatalog</b> : spécifié le nom de votre cluster en utilisant le format * &lt;le nom de votre cluster&gt;. azurehdinsight.net.*<br/><br/><b>Nom du compte utilisateur Hadoop</b>: Spécifie le nom du compte utilisateur Hadoop utilisé pour mettre en service le cluster.<br/><br/><b>Mot de passe utilisateur Hadoop</b> : Spécifie les informations d’identification utilisées lors de la configuration du cluster. Pour plus d’informations, consultez [Hadoop de créer des clusters dans HDInsight](../hdinsight/hdinsight-provision-clusters.md).<br/><br/><b>Emplacement des données de sortie</b>: Spécifie si les données sont stockées dans un système de fichiers distribué de Hadoop (très) ou dans Azure. <br/><ul>Si vous stockez les données de sortie de très, spécifiez l’URI du serveur très. (Veillez à utiliser le nom du cluster HDInsight sans le préfixe HTTPS://). <br/><br/>Si vous stockez vos données de sortie dans Azure, vous devez spécifier le nom du compte de stockage Azure, la clé d’accès de stockage et le nom du conteneur de stockage.</ul>|
Base de données SQL |Lit les données qui sont stockées dans une base de données Azure SQL ou dans une base de données SQL Server en cours d’exécution sur une machine virtuelle Azure. | <b>Nom du serveur de base de données</b>: Spécifie le nom du serveur sur lequel la base de données est en cours d’exécution.<br/><ul>Permet d’entrer le nom du serveur qui est généré en cas de base de données de SQL Azure. Il possède généralement le formulaire * &lt;generated_identifier&gt;. database.windows.net.* <br/><br/>Dans le cas d’un serveur SQL hébergé sur un ordinateur virtuel d’Azure, entrez *tcp :&lt;nom de DNS de Machine virtuelle&gt;, 1433*</ul><br/><b>Nom de la base de données </b>: Spécifie le nom de la base de données sur le serveur. <br/><br/><b>Nom du compte utilisateur Server</b>: Spécifie un nom d’utilisateur pour un compte qui dispose des autorisations d’accès pour la base de données. <br/><br/><b>Mot de passe utilisateur serveur</b>: Spécifie le mot de passe pour le compte d’utilisateur.<br/><br/><b>Accepter un certificat de serveur</b>: utilisez cette option (moins sûre) si vous souhaitez ignorer la vérification du certificat du site avant de lire vos données.<br/><br/><b>Requête de base de données</b>: entrez une instruction SQL qui décrit les données que vous souhaitez lire.|
Base de données SQL sur site |Lit les données qui sont stockées dans une base de données SQL sur site. | <b>Passerelle de données</b>: Spécifie le nom de la passerelle de gestion des données installé sur un ordinateur où elle peut accéder à votre base de données SQL Server. Pour plus d’informations sur la configuration de la passerelle, consultez [effectuer avancée analytique avec formation de Machine Azure à l’aide de données d’un serveur SQL de locaux](machine-learning-use-data-from-an-on-premises-sql-server.md).<br/><br/><b>Nom du serveur de base de données</b>: Spécifie le nom du serveur sur lequel la base de données est en cours d’exécution.<br/><br/><b>Nom de la base de données </b>: Spécifie le nom de la base de données sur le serveur. <br/><br/><b>Nom du compte utilisateur Server</b>: Spécifie un nom d’utilisateur pour un compte qui dispose des autorisations d’accès pour la base de données. <br/><br/><b>Nom d’utilisateur et le mot de passe</b>: cliquez sur <b>Entrez des valeurs</b> pour entrer vos informations d’identification de base de données. Vous pouvez utiliser l’authentification intégrée de Windows ou l’authentification SQL Server en fonction de la configuration de votre du SQL Server local.<br/><br/><b>Requête de base de données</b>: entrez une instruction SQL qui décrit les données que vous souhaitez lire.|
Table Azure|Lit les données à partir du service de la Table dans le stockage Azure.<br/><br/>Si vous lisez rarement des grandes quantités de données, utilisez le Service de la Table Azure. Il fournit un flexible, non relationnelles (NoSQL), solution de stockage haute disponibilité, économique et hautement évolutives.| Les options de l' **Importation de données** changent selon que vous accédez à des informations publiques ou un compte de stockage privé qui nécessite des informations d’identification. Cela est déterminé par le <b>Type d’authentification</b> qui peut avoir la valeur « PublicOrSAS » ou « Compte », chacun d’eux a son propre jeu de paramètres. <br/><br/><b>Public ou partagé accès Signature (SAS) URI</b>: les paramètres sont :<br/><br/><ul><b>URI de la table</b>: Spécifie le Public ou l’URL de SAS pour la table.<br/><br/><b>Spécifie les lignes à rechercher les noms de propriété</b>: les valeurs sont <i>TopN</i> pour analyser le nombre spécifié de lignes, ou <i>ScanAll</i> pour obtenir toutes les lignes de la table. <br/><br/>Si les données sont homogènes et prévisibles, il est recommandé que vous sélectionnez *TopN* et entrez un nombre pour N. Pour les tables volumineuses, cela peut entraîner des temps de lecture plus rapide.<br/><br/>Si les données sont structurées avec les jeux de propriétés qui varient en fonction de la profondeur et la position de la table, cliquez sur l’option *ScanAll* pour analyser toutes les lignes. Cela garantit l’intégrité de votre propriété résultante et la conversion de métadonnées.<br/><br/></ul><b>Compte de stockage privé</b>: les paramètres sont : <br/><br/><ul><b>Nom de compte</b>: Spécifie le nom du compte qui contient la table à lire.<br/><br/><b>Clé de compte</b>: Spécifie la clé de stockage associée au compte.<br/><br/><b>Nom de la table</b> : Spécifie le nom de la table qui contient les données à lire.<br/><br/><b>Lignes à analyser pour les noms de propriété</b>: les valeurs sont <i>TopN</i> pour analyser le nombre spécifié de lignes, ou <i>ScanAll</i> pour obtenir toutes les lignes de la table.<br/><br/>Si les données sont homogènes et prévisibles, nous recommandons que vous sélectionnez *TopN* et entrez un nombre pour N. Pour les tables volumineuses, cela peut entraîner des temps de lecture plus rapide.<br/><br/>Si les données sont structurées avec les jeux de propriétés qui varient en fonction de la profondeur et la position de la table, cliquez sur l’option *ScanAll* pour analyser toutes les lignes. Cela garantit l’intégrité de votre propriété résultante et la conversion de métadonnées.<br/><br/>|
Stockage des objets Blob Azure | Lit les données stockées dans le service d’objet Blob dans le stockage Azure, y compris les images, de texte non structuré ou de données binaires.<br/><br/>Vous pouvez utiliser le service d’objet Blob pour exposer publiquement des données ou pour stocker en privé des données d’application. Vous pouvez accéder à vos données depuis n’importe où en utilisant des connexions HTTP ou HTTPS. | Les options dans le module **d’Importation de données** varient selon que vous accédez à des informations publiques ou un compte de stockage privé qui nécessite des informations d’identification. Cela est déterminé par le <b>Type d’authentification</b> , qui peut avoir une valeur de « PublicOrSAS » ou « Compte ».<br/><br/><b>Public ou partagé accès Signature (SAS) URI</b>: les paramètres sont :<br/><br/><ul><b>URI</b>: Spécifie le Public ou l’URL de SAS pour le blob de stockage.<br/><br/><b>Format de fichier</b>: Spécifie le format des données dans le service d’objet Blob. Les formats pris en charge sont ARFF, CSV et TSV.<br/><br/></ul><b>Compte de stockage privé</b>: les paramètres sont : <br/><br/><ul><b>Nom de compte</b>: Spécifie le nom du compte qui contient l’objet blob que vous souhaitez lire.<br/><br/><b>Clé de compte</b>: Spécifie la clé de stockage associée au compte.<br/><br/><b>Chemin d’accès au conteneur, répertoire ou blob</b> : Spécifie le nom de l’objet blob qui contient les données à lire.<br/><br/><b>Format de fichier BLOB</b>: Spécifie le format des données dans le service d’objet blob. Les formats de données pris en charge sont CSV, TSV, ARFF, CSV, avec un codage spécifique et Excel. <br/><br/><ul>Si le format est CSV ou TSV, veillez à indiquer si le fichier contient une ligne d’en-tête.<br/><br/>Vous pouvez utiliser l’option Excel pour lire des données dans des classeurs Excel. Dans l’option de <i>format de données d’Excel</i> , vous pouvez indiquer si les données sont dans une plage de feuille de calcul Excel ou d’un tableau Excel. Dans l’option <i>feuille de calcul Excel ou un tableau incorporé </i>, spécifiez le nom de la feuille ou la table que vous souhaitez lire.</ul><br/>|
Fournisseur de flux de données | Lit les données à partir d’un fournisseur d’alimentation pris en charge. Actuellement uniquement le format Open Data Protocol (OData) est pris en charge. | <b>Type de données de contenu</b>: Spécifie le format OData.<br/><br/><b>Source URL</b>: Spécifie l’URL complète pour le flux de données. <br/>Par exemple, l’URL suivante lit à partir de la base de données exemple Les Comptoirs : http://services.odata.org/northwind/northwind.svc/|


<!-- Module References -->
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[export-data]: https://msdn.microsoft.com/library/azure/7A391181-B6A7-4AD4-B82D-E419C0D6522C/
